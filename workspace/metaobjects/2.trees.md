## Prototype Chains and Trees {#trees}

As we've noted repeatedly, JavaScript's built-in metaobjects are called *prototypes*. There are several ways to create an object in JavaScript, and three of them associate the newly created object with a prototype:

1. We can use the `new` operator with a function, e.g. `new Object()`. This particular newly created object delegates its behaviour to `Object.prototype`, but any function will do, and the newly created object will delegate its behaviour to the function's `.prototype` property.
2. We can use the object literal syntax, e.g. `{ number: 6 }`. The newly created object always delegates its behaviour to `Object.prototype`.
3. We can call `Object.create(somePrototype)` and pass in any object. The newly created object will delegate its behaviour to `somePrototype`.
4. We can call `Object.create(null)`, and the newly created object won't delegate its behaviour at all.

No matter how we create an object, we can get its prototype using `Object.getPrototypeOf`:

    function Something () {}

    var object = new Something();

    Object.getPrototypeOf(object) === Something.prototype
      //=> true

JavaScript provides several options for making sense of this arrangement at runtime. We've seen `Object.getPrototypeOf`. Another is `.hasOwnProperty`. Objects that directly or indirectly have `Object.prototype` as one of their prototypes can use this method to test whether a property is defined in the object itself. To whit:

    var P = {
      foo: 'SNAFU'
    };

    var obj = Object.create(P);
    obj.bar = 'Italia';

    obj.hasOwnProperty('foo')
      //=> false

    obj.hasOwnProperty('bar')
      //=> true

In earlier releases of JavaScript, this could be used to enumerate over an object's domain properties with code like this:

    var ownProperties = [];

    for (var i in obj) {
      if (obj.hasOwnProperty(i)) {
        ownProperties.push(i);
      }
    }
    ownProperties
      //=> [ 'bar' ]

What about objects that don't directly or indirectly delegate to `Object.prototype`?

    var P2 = Object.create(null);
    P2.foo = 'SNAFU'

    var obj2 = Object.create(P2);
    obj2.bar = 'Italia';

    obj2.hasOwnProperty('foo')
      //=> TypeError: Object object has no method 'hasOwnProperty'

We can still use this method, we just need to do it indirectly:

    Object.prototype.hasOwnProperty.call(obj2, 'bar')
      //=> true

JavaScript now gives us more elegant tools:

    Object.defineProperty(obj2, 'hidden', {
      enumerable: false,
      value: 'secret'
    });

    Object.keys(obj2)
      //=> [ 'bar' ]

    Object.getOwnPropertyNames(obj2)
      //=> [ 'bar', 'hidden' ]

`Object.keys` returns the objects own properties that are enumerable. `Object.getOwnPropertyNames` returns all of the object's own property names, enumerable or not. And the `for... in...` loop iterates over all of an object's properties, including those available through delegation to prototypes.

### ontologies

For the last forty years, people have fallen into the trap of trying to organize their knowledge about a domain into an *ontology*:

> Traditionally listed as a part of the major branch of philosophy known as metaphysics, ontology deals with questions concerning what entities exist or can be said to exist, and how such entities can be grouped, related within a hierarchy, and subdivided according to similarities and differences.â€”[Wikipedia](https://en.wikipedia.org/wiki/Ontology)

The ontology describes the behaviour we can expect of objects by assigning them to ad hoc sets. These objects are accounts, those objects are commands. Sets can have sub-sets that have refined or specialized expectation: These objects are chequing accounts, they behave like accounts and they also have these behaviours specific to chequing accounts.

There are various ways to organize such ontologies. The simplest is to arrange everything in a strict tree.

JavaScript's prototypes are very well suited for organizing the behaviour of objects into a tree-like ontology. Let us say that we are modeling DOM elements. All elements have `.name()` and `.document()` methods. We model this with a prototype:

    var ElementPrototype = extend(Object.create(null), {
      document: function () {
        return this._document;
      },
      name: function () {
        return this._name;
      }
    });

Now, some elements are containers that hold a list of children. We want our `Container` elements to also have all the methods and properties of an `ElementPrototype`, so we give our prototype... A prototype of its own:

    var ContainerPrototype = extend(Object.create(ElementPrototype), {
      children: function () {
        return this._children;
      }
    });

Now, anything that delegates to `ContainerPrototype` will behave as if it has all of `ContainerPrototype`'s methods: They delegate `.children` directly to `ContainerPrototype`, and they delegate `.document` and `.name` to `ContainerDelegate`, then `ContainerDelegate` in turn delegates them to `ElementPrototype`.

We don't have to define just methods, a prototype can hold any property or properties:

    var ParagraphPrototype = extend(Object.create(ContainerPrototype), {
      _name: 'p';
    });

Just as several concrete objects can share the same prototype, several prototypes can share the same prototype:

    var TextPrototype = extend(Object.create(ElementPrototype), {
      text: function () {
        return this._text;
      }
    });

Objects that delegate methods to `TextPrototype` also delegate methods, indirectly, to `ElementPrototype`, just as objects that delegate properties to `ParagraphPrototype` also delegate properties, indirectly, to `ContainerPrototype` and `ElementPrototype`.

In this manner, programmers can build elaborate trees of prototypes, with each prototype having a small and carefully focused responsibility. Each concrete domain object obtains behaviour from a leaf of the tree.

The drawback of this arrangement is that the various objects and prototypes are now *tightly coupled*. Changes to any one prototype ripple through the tree. The entire arrangement becomes fragile. What looked at first to be highly flexible grows over time to be highly inflexible.

### the natural tension between redundancy and coupling

There is a general principle at work here. In theory, you could write a "Kompressor" program: It would read a JavaScript program and remove all duplication it finds, replacing duplication with indirection through function calls, prototypes, &c.

You could feed the output of Kompressor back into itself, removing more redundancy, until the output had reached maximum compression. From an information-theory perspective, the number of bits in the result represents the information in the original program. There is no redundancy.

However, this misses the idea that programs change over time. A written program contains bits of information about how to transform its inputs into its outputs, but it also contains bits of information designed to guide changes in the future.

A program that has been "maximally compressed" is now also maximally coupled. Changes to any one bit of information in the program may affect its behaviour in wildly unpredictable ways.

Whereas, a program that has been well-crafted deliberately decouples things that are unrelated. This increases the predictability of change, at the cost of program size. There is a natural *tension* between redundancy and coupling: A program that removes all redundancy naturally increases its coupling.